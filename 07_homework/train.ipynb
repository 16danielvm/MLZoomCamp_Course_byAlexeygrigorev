{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 'https://raw.githubusercontent.com/alexeygrigorev/mlbookcamp-code/master/chapter-06-trees/CreditScoring.csv'\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()\n",
    "\n",
    "status_values = {\n",
    "    1: 'ok',\n",
    "    2: 'default',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.status = df.status.map(status_values)\n",
    "\n",
    "home_values = {\n",
    "    1: 'rent',\n",
    "    2: 'owner',\n",
    "    3: 'private',\n",
    "    4: 'ignore',\n",
    "    5: 'parents',\n",
    "    6: 'other',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.home = df.home.map(home_values)\n",
    "\n",
    "marital_values = {\n",
    "    1: 'single',\n",
    "    2: 'married',\n",
    "    3: 'widow',\n",
    "    4: 'separated',\n",
    "    5: 'divorced',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.marital = df.marital.map(marital_values)\n",
    "\n",
    "records_values = {\n",
    "    1: 'no',\n",
    "    2: 'yes',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.records = df.records.map(records_values)\n",
    "\n",
    "job_values = {\n",
    "    1: 'fixed',\n",
    "    2: 'partime',\n",
    "    3: 'freelance',\n",
    "    4: 'others',\n",
    "    0: 'unk'\n",
    "}\n",
    "\n",
    "df.job = df.job.map(job_values)\n",
    "\n",
    "for c in ['income', 'assets', 'debt']:\n",
    "    df[c] = df[c].replace(to_replace=99999999, value=np.nan)\n",
    "\n",
    "df = df[df.status != 'unk'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=11)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = (df_train.status == 'default').astype('int').values\n",
    "y_test = (df_test.status == 'default').astype('int').values\n",
    "\n",
    "del df_train['status']\n",
    "del df_test['status']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dicts = df_train.fillna(0).to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dicts)\n",
    "\n",
    "test_dicts = df_test.fillna(0).to_dict(orient='records')\n",
    "X_test = dv.transform(test_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, min_samples_leaf=3, n_estimators=200,\n",
       "                       random_state=1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=200,\n",
    "                            max_depth=10,\n",
    "                            min_samples_leaf=3,\n",
    "                            random_state=1)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "XGBoost\n",
    "\n",
    "Note:\n",
    "\n",
    "We removed feature names\n",
    "\n",
    "It was\n",
    "\n",
    "features = dv.get_feature_names_out()\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train, feature_names=features)\n",
    "\n",
    "Now it's\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = {\n",
    "    'eta': 0.1, \n",
    "    'max_depth': 3,\n",
    "    'min_child_weight': 1,\n",
    "\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "\n",
    "    'nthread': 8,\n",
    "    'seed': 1,\n",
    "    'verbosity': 1,\n",
    "}\n",
    "\n",
    "model = xgb.train(xgb_params, dtrain, num_boost_round=175)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bento ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bentoml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(tag=\"credit_risk_model:f3vybdcs5kifmedc\", path=\"C:\\Users\\tuto\\bentoml\\models\\credit_risk_model\\f3vybdcs5kifmedc\\\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bentoml.xgboost.save_model(\n",
    "    'credit_risk_model',\n",
    "    model,\n",
    "    custom_objects={\n",
    "        'dictVectorizer': dv\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2\n",
    "\n",
    "Run the notebook which contains the xgboost model from module 6 i.e previous module and save the xgboost model with BentoML. To make it easier for you we have prepared this notebook.\n",
    "\n",
    "How big approximately is the saved BentoML model? Size can slightly vary depending on your local development environment. Choose the size closest to your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " credit_risk_model:f3vybdcs5kifmedc  bentoml.xgboost  197.75 KiB  2022-10-23 10:48:48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 3\n",
    "\n",
    "Say you have the following data that you're sending to your service:\n",
    "\n",
    "{\n",
    "  \"name\": \"Tim\",\n",
    "  \"age\": 37,\n",
    "  \"country\": \"US\",\n",
    "  \"rating\": 3.14\n",
    "}\n",
    "\n",
    "What would the pydantic class look like? You can name the class UserProfile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class UserProfile(BaseModel):\n",
    "    \n",
    "    name: str,\n",
    "    \n",
    "    age: int,\n",
    "    \n",
    "    country: str,\n",
    "    \n",
    "    rating: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 4\n",
    "\n",
    "We've prepared a model for you that you can import using:\n",
    "\n",
    "curl -O https://s3.us-west-2.amazonaws.com/bentoml.com/mlzoomcamp/coolmodel.bentomodel\n",
    "bentoml models import coolmodel.bentomodel\n",
    "\n",
    "What version of scikit-learn was this model trained with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- name: mlzoomcamp_homework\n",
    "- version: qtzdz3slg6mwwdu5\n",
    "- module: bentoml.sklearn\n",
    "- labels: {}\n",
    "- options: {}\n",
    "- metadata: {}\n",
    "- context:\n",
    "  - framework_name: sklearn\n",
    "  - framework_versions:\n",
    "    - scikit-learn: 1.1.1\n",
    "  - bentoml_version: 1.0.7\n",
    "  - python_version: 3.9.12\n",
    "- signatures:\n",
    "  - predict:\n",
    "    - batchable: false\n",
    "- api_version: v1\n",
    "- creation_time: '2022-10-13T20:42:14.411084+00:00'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 5\n",
    "\n",
    "Create a bento out of this scikit-learn model. The output type for this endpoint should be NumpyNdarray()\n",
    "\n",
    "Send this array to the Bento:\n",
    "\n",
    "[[6.4,3.5,4.5,1.2]]\n",
    "\n",
    "You can use curl or the Swagger UI. What value does it return?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 6\n",
    "\n",
    "Which model has better performance at higher volumes?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 7 (optional)\n",
    "\n",
    "Go to this Bento deployment of Stable Diffusion: http://54.176.205.174/ (or deploy it yourself)\n",
    "\n",
    "Use the txt2image endpoint and update the prompt to: \"A cartoon dragon with sunglasses\". Don't change the seed, it should be 0 by default\n",
    "\n",
    "What is the resulting image?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46327b6bb16798f80635706720d32319bb9fd65aa2f1c2afb04f8d6b7da62462"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
